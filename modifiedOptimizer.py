import tensorflow as tf
import keras

from dataLoader import DataLoder
from buildModel import ModelBuilder, N, STEPS, LOSS, BATCH_SIZE, NUMOFCLASS

import matplotlib.pyplot as plt
import random
import numpy as np
import os

class optimizer:
    
    def pso(self, psoMdoel, x_train, y_train, acc=0.4, local_acc=0.6, global_acc=1.0):
        parm = {'acc':acc, 'local_acc':local_acc, 'global_acc':local_acc}
        
        best_model = None
        best_score = 0.0
        best_weight = psoMdoel.get_weights()

        particles = [None] * N
        particle_acc = [None] * N
        particle_local_best_weight = [best_weight] * N

        plot_loss = [[]] * N
        plot_acc = [[]] * N
        
        #velocity initial
        velocities = [None] * len(best_weight)
        for i, layer in enumerate(best_weight):
            velocities[i] = np.random.rand(*layer.shape) / 5 - 0.10

        # initial particle
        for p in range(N) :
            particles[p] = psoMdoel
            particles[p].compile(loss=LOSS, optimizer='adam', metrics=['accuracy'])
            plot_acc[p] = [0]
            plot_loss[p] = [3]

        # step size * particle size iteration
        for i in range(STEPS) :
            print("################# {}번 째 epoch 실행 중##################".format(i))
            for num_p in range(N) :
                print("{}번 째 particle".format(num_p))

                step_weight = particles[num_p].get_weights()
                new_velocities = [None] * len(step_weight)
                new_weight = [None] * len(step_weight)
                local_rand, global_rand = random.random(), random.random()

                for index, layer in enumerate(step_weight):
                    new_v = parm['acc'] * velocities[index]
                    new_v = new_v + parm['local_acc'] * local_rand * (particle_local_best_weight[num_p][index] - layer)
                    new_v = new_v + parm['global_acc'] * global_rand * (best_weight[index] - layer)
                    new_velocities[index] = new_v
                    new_weight[index] = step_weight[index] + new_velocities[index]

                particles[num_p].set_weights(new_weight)

                hist = particles[num_p].fit(x_train, y_train,
                        epochs=1,
                        verbose=1,
                        validation_split=0.1)

                train_score_loss = hist.history['loss'][-1]
                train_score_acc = hist.history['accuracy'][-1]
                
                plot_loss[num_p].append(train_score_loss)
                plot_acc[num_p].append(train_score_acc)

                particle_acc[num_p] = train_score_acc

                if best_score <= train_score_acc:
                    particle_local_best_weight[num_p] = particles[num_p].get_weights()
                
                print("loss:", train_score_loss)
                print("acc:", train_score_acc)

            
            for i, acc in enumerate(particle_acc) :
                if best_score <= acc  :
                    best_model = particles[i]
                    best_score = acc
                    best_weight = particles[i].get_weights()
            
        self.drawPlot(arr=plot_acc, 
            saveDir='./pso/acc/PSO_acc_N_{}_STEP_{}_BATCH_{}'.format(N, STEPS, BATCH_SIZE),
            label='acc_paritcle_{}',
            xlabel='epoch', 
            ylabel='acc',
            isAcc=True)
        self.drawPlot(arr=plot_loss, 
            saveDir='./pso/loss/PSO_loss_N_{}_STEP_{}_BATCH_{}'.format(N, STEPS, BATCH_SIZE),
            label='loss_paritcle_{}',
            xlabel='epoch', 
            ylabel='loss')
                
        return best_model

    """
    @author Mike Holcomb (mjh170630@utdallas.edu)
    """
    def vanilla_backpropagation(self, vanillaModel, x_train, y_train):
        '''
        Runs N number of backpropagation model training simulations
        :param x_train: x values to train on
        :param y_train: target labels to train with
        :return: best model run as measured by LOSS
        '''
        best_model = None
        best_score = 100.0
        lossList = []

    
        for i in range(N):
            model_s = vanillaModel.build_model(LOSS)
            hist = model_s.fit(x_train, y_train,
                        epochs=STEPS,
                        batch_size=BATCH_SIZE,
                        verbose=1,
                        validation_split=0.1)
            train_score = model_s.evaluate(x_train, y_train, batch_size=BATCH_SIZE, verbose=1)
            print("now vanilla is running", i)
            print(train_score)

            if train_score[0] < best_score: # loss 
                best_model = model_s
                best_score = train_score[0]

            #visualization
            _, loss_ax = plt.subplots()

            loss_ax.plot(hist.history['loss'], 'y', label='train loss')
            loss_ax.set_xlabel('epoch')
            loss_ax.set_ylabel('loss')
            loss_ax.legend(loc='upper left')
            plt.savefig('./vanilla/loss/loss_Vanilla_{}_N_{}_STEP_{}_BATCH_{}.png'.format(i, N, STEPS, BATCH_SIZE))

            _, acc_ax = plt.subplots()
            acc_ax.plot(hist.history['accuracy'], 'b', label='train acc')
            acc_ax.set_xlabel('epoch')
            acc_ax.set_ylabel('accuracy')
            acc_ax.set_ylim(0,1)
            acc_ax.legend(loc='upper left')
            plt.savefig('./vanilla/acc/acc_Vanilla_{}_N_{}_STEP_{}_BATCH_{}.png'.format(i, N, STEPS, BATCH_SIZE))


            lossList.append([str(i), str(train_score[0])])
            

        return best_model, lossList
    
    def drawPlot(self, arr, saveDir, label='{}', xlabel='epoch', ylabel='loss', isAcc=False):
        for i, a in enumerate(arr):
            plt.plot(range(STEPS + 1), a, label=label.format(i))
        
        plt.xlabel(xlabel)
        plt.ylabel(ylabel)
        if isAcc: plt.ylim(0,1)
        plt.legend(loc='upper left')
        plt.savefig(os.getcwd() + saveDir)
        plt.clf()